# verify_encodings.py
"""
Verify encoded SDR pickles generated by main_encoder.py.

Usage examples:
  python verify_encodings.py --pkl encoded_sdrs/video1_sdr.pkl
  python verify_encodings.py --pkl encoded_sdrs/video1_sdr.pkl --npz data/flow_video1_flow.npz --recheck-frames 5

What it does:
 - Loads the pickle and inspects structure (T frames x C cells).
 - Determines whether each cell item is an SDR object (has .sparse) or an np.ndarray of indices.
 - Computes stats: active bits distribution, empty cells fraction, per-cell inferred input_size.
 - Determinism checks: reloads file and compares content equality.
 - Optional re-encode verification: given original .npz and same encoder code, re-encode first N frames and compare indices.
"""

from __future__ import annotations
import argparse, pickle, os, sys
import numpy as np
from typing import Any, List, Tuple

try:
    from htm.bindings.sdr import SDR
except Exception:
    SDR = None  # if HTM binding unavailable, still support numpy representation

# If you saved sparse index np.arrays, they'll be numpy arrays of dtype int.
def extract_indices(item: Any) -> np.ndarray:
    """
    Given either an SDR-like object (has .sparse) or an ndarray, return a 1D int ndarray of indices.
    """
    if item is None:
        return np.array([], dtype=np.int32)
    if hasattr(item, "sparse"):
        arr = getattr(item, "sparse")
        return np.array(arr, dtype=np.int32)
    # if it's already a numpy array-like
    arr = np.asarray(item)
    if arr.ndim == 0:
        # scalar -> treat as empty
        return np.array([], dtype=np.int32)
    return arr.astype(np.int32)

import pickle, numpy as np, os

def load_encoded_file(path: str):
    """
    Load either a pickled object (.pkl) or a numpy .npz archive and
    return a normalized Python structure:
      frames = [ frame0, frame1, ... ]
      where frameX = [ cell0_indices, cell1_indices, ... ]
      and each cell*_indices is a 1D np.int32 array.

    This keeps the rest of the script unchanged.
    """
    ext = os.path.splitext(path)[1].lower()
    if ext == ".pkl":
        with open(path, "rb") as f:
            return pickle.load(f)

    if ext in (".npz", ".npz".upper()):
        npz = np.load(path, allow_pickle=True)
        # Try a set of likely keys
        key_candidates = ["indices", "arr", "frames", "data"]
        key = None
        for k in key_candidates:
            if k in npz:
                key = k
                break
        # If only one array in the archive, use that
        if key is None:
            keys = list(npz.keys())
            if len(keys) == 1:
                key = keys[0]
            else:
                # fallback: try to interpret 'indices' not present
                raise ValueError(f"NPZ file contains multiple arrays {list(npz.keys())}; could not pick which to use. Save under 'indices' key.")

        arr = npz[key]

        # Case A: arr is a 3D numeric array shape (T, cells, active_bits)
        if isinstance(arr, np.ndarray) and arr.dtype != object and arr.ndim == 3:
            T, cells, active_bits = arr.shape
            frames = []
            for t in range(T):
                # each cell currently arr[t, c, :] -> 1D array of indices
                frame = []
                for c in range(cells):
                    indices = np.asarray(arr[t, c], dtype=np.int32)
                    frame.append(indices)
                frames.append(frame)
            return frames

        # Case B: arr is an object array (e.g. list-of-frames saved)
        if isinstance(arr, np.ndarray) and arr.dtype == object:
            # Two possible shapes:
            # - arr is (T,) with each arr[t] being list-of-cells (each a 1D array)
            # - arr is (T, cells) with each arr[t,c] a 1D array
            if arr.ndim == 1:
                frames = []
                for t in range(arr.shape[0]):
                    frame_raw = arr[t]
                    # frame_raw might be a list/ndarray of cell arrays
                    if frame_raw is None:
                        frames.append([])
                        continue
                    frame = [np.asarray(cell, dtype=np.int32) for cell in frame_raw]
                    frames.append(frame)
                return frames
            elif arr.ndim == 2:
                T, cells = arr.shape
                frames = []
                for t in range(T):
                    frame = [np.asarray(arr[t, c], dtype=np.int32) for c in range(cells)]
                    frames.append(frame)
                return frames

        # Case C: arr is 2D numeric array (T, active_bits) meaning single-cell-per-frame
        if isinstance(arr, np.ndarray) and arr.dtype != object and arr.ndim == 2:
            T, active_bits = arr.shape
            frames = []
            for t in range(T):
                # treat as single cell per frame
                frames.append([np.asarray(arr[t, :], dtype=np.int32)])
            return frames

        raise ValueError("Unsupported .npz storage layout for indices. Please save under key 'indices' with shape (T, cells, active_bits) or as object array of per-frame cell arrays.")

    # unsupported extension
    raise ValueError("Unsupported file extension for encoded SDRs: " + ext)


def inspect_structure(data: Any) -> Tuple[int, int]:
    """
    Expect top-level to be sequence of frames, where each frame is sequence of cells.
    Return (num_frames, cells_per_frame)
    """
    if not isinstance(data, (list, tuple, np.ndarray)):
        raise ValueError("Unsupported pickle top-level type: %s" % type(data))
    num_frames = len(data)
    cells_per_frame = None
    for frame in data:
        if not isinstance(frame, (list, tuple, np.ndarray)):
            raise ValueError("Each frame should be a sequence of cells. Found: %s" % type(frame))
        if cells_per_frame is None:
            cells_per_frame = len(frame)
    if cells_per_frame is None:
        cells_per_frame = 0
    return num_frames, cells_per_frame

def summarize(data: Any, sample_frames: int = 5):
    num_frames, cells = inspect_structure(data)
    print(f"Loaded pickle: frames={num_frames}, cells/frame={cells}")
    # gather stats
    active_counts = []
    max_index_seen = -1
    empty_cells = 0
    # iterate but cap iterations to avoid huge runtime
    max_check_frames = min(num_frames, sample_frames)
    frames_to_check = list(range(max_check_frames))
    # also check last few frames
    last_samples = list(range(max(0, num_frames - max_check_frames), num_frames))
    indices_to_check = sorted(set(frames_to_check + last_samples))
    for fi in indices_to_check:
        frame = data[fi]
        for cell in frame:
            idx = extract_indices(cell)
            active_counts.append(len(idx))
            if idx.size == 0:
                empty_cells += 1
            if idx.size:
                max_index_seen = max(max_index_seen, int(idx.max()))
    active_counts = np.array(active_counts, dtype=np.int32) if active_counts else np.array([], dtype=np.int32)
    if active_counts.size == 0:
        print("Warning: no active bits observed in sampled frames.")
    else:
        print(f"Active bits (sampled cells): min={int(active_counts.min())}, max={int(active_counts.max())}, mean={float(active_counts.mean()):.2f}")
    tot_sampled_cells = len(indices_to_check) * cells if cells else 0
    if tot_sampled_cells > 0:
        print(f"Empty cells in sampled frames: {empty_cells}/{tot_sampled_cells} ({100.0 * empty_cells / tot_sampled_cells:.2f}%)")
    if max_index_seen >= 0:
        inferred_input_size = max_index_seen + 1
        print(f"Inferred input size (from max index seen + 1): {inferred_input_size}")
    else:
        print("Could not infer input size (no indices found in samples).")
    # more detailed histogram of active counts
    if active_counts.size:
        unique, counts = np.unique(active_counts, return_counts=True)
        print("Active-bits histogram (sample):")
        for u, c in zip(unique, counts):
            print(f"  {u} bits -> {c} cells")
    return {
        "num_frames": num_frames,
        "cells_per_frame": cells,
        "sampled_cells_checked": tot_sampled_cells,
        "empty_cells": empty_cells,
        "inferred_input_size": (max_index_seen + 1) if max_index_seen >= 0 else None,
        "active_counts_sample": active_counts
    }

def compare_pickles_bytes(path: str) -> bool:
    """
    Load twice and compare serialized bytes. This is a quick check that file content is stable.
    """
    b1 = open(path, "rb").read()
    b2 = open(path, "rb").read()
    return b1 == b2

def deep_compare_loaded(data1: Any, data2: Any) -> bool:
    """
    Compare two loaded structures by comparing per-cell index arrays.
    Returns True if identical.
    """
    try:
        nf1, cf1 = inspect_structure(data1)
        nf2, cf2 = inspect_structure(data2)
    except Exception as e:
        print("Structure mismatch during deep compare:", e)
        return False
    if nf1 != nf2 or cf1 != cf2:
        print("Different shapes: ", (nf1, cf1), "vs", (nf2, cf2))
        return False
    for i in range(nf1):
        f1 = data1[i]
        f2 = data2[i]
        for j in range(cf1):
            a = extract_indices(f1[j])
            b = extract_indices(f2[j])
            if a.shape != b.shape:
                print(f"Mismatch at frame {i} cell {j}: shape {a.shape} vs {b.shape}")
                return False
            if a.size and not np.array_equal(a, b):
                print(f"Content mismatch at frame {i} cell {j}: first indices differ")
                return False
    return True

def reencode_and_compare(pkl_data: Any, npz_path: str, recheck_frames: int = 3):
    """
    If original .npz exists, re-encode first recheck_frames frames and compare saved indices.
    Requires that encoder.OpticalFlowEncoder is importable from your project (same params).
    """
    print(f"\nAttempting re-encode verification using {npz_path} (first {recheck_frames} frames)...")
    if not os.path.exists(npz_path):
        print("Provided npz path does not exist.")
        return False
    try:
        from encoder import OpticalFlowEncoder
    except Exception as e:
        print("Could not import encoder.OpticalFlowEncoder:", e)
        return False

    arr = np.load(npz_path)
    if 'motion_vectors' not in arr:
        print("npz file missing 'motion_vectors' key.")
        return False
    flows = arr['motion_vectors']
    encoder = OpticalFlowEncoder()
    # re-encode first frames of flows -> produce frames of cell lists like pkl_data
    T = min(recheck_frames, flows.shape[0])
    # We must infer grid dims from pkl_data: assume pkl_data[0] gives number of cells; we cannot map location to patch easily here,
    # so we only support the case where the pickle saved per-frame cells in the same order as main_encoder: row-major 5x5 etc.
    # Ask user for grid dims if needed; but try default 5x5 layout by inferring cells_per_frame.
    num_frames, cells_per_frame = inspect_structure(pkl_data)
    if cells_per_frame is None or cells_per_frame == 0:
        print("Cannot infer cells_per_frame from pickle; aborting re-encode check.")
        return False

    # Infer grid shape as best-effort: prefer square factors
    # naive heuristic: try to find r x c such that r*c == cells_per_frame and r close to c
    def infer_grid(k):
        for r in range(int(np.sqrt(k)), 0, -1):
            if k % r == 0:
                return r, k // r
        return 1, k
    grid_r, grid_c = infer_grid(cells_per_frame)
    print(f"Assuming grid {grid_r} x {grid_c} = {cells_per_frame} cells (heuristic).")

    # compute cell slice dims from flows shape (H,W)
    H = int(flows.shape[1])
    W = int(flows.shape[2])
    cell_h = H // grid_r
    cell_w = W // grid_c

    mismatches = 0
    for t in range(T):
        flow = flows[t]
        # build cell encodings
        re_frame = []
        for i in range(grid_r):
            for j in range(grid_c):
                y0 = i * cell_h
                y1 = (i + 1) * cell_h if i < grid_r - 1 else H
                x0 = j * cell_w
                x1 = (j + 1) * cell_w if j < grid_c - 1 else W
                patch = flow[y0:y1, x0:x1]
                sdr = encoder.encode(patch)
                re_frame.append(extract_indices(sdr))
        # compare to saved frame
        saved_frame = pkl_data[t]
        for c in range(cells_per_frame):
            saved_idx = extract_indices(saved_frame[c])
            re_idx = re_frame[c]
            if not np.array_equal(saved_idx, re_idx):
                mismatches += 1
                # print a single example mismatch for debugging
                if mismatches <= 5:
                    print(f"Mismatch frame {t} cell {c}: saved (len={saved_idx.size}) vs re-encoded (len={re_idx.size})")
    if mismatches == 0:
        print("Re-encode check: OK, no mismatches found in sampled frames.")
        return True
    else:
        print(f"Re-encode check: found {mismatches} mismatches in sampled frames (first {T} frames).")
        return False

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--pkl", required=True, help="Path to encoded SDR pickle")
    ap.add_argument("--npz", required=False, help="Optional original optical-flow .npz file to re-encode and compare")
    ap.add_argument("--recheck-frames", type=int, default=3, help="How many frames to re-encode for comparison")
    ap.add_argument("--sample-frames", type=int, default=5, help="How many frames to sample for stats")
    args = ap.parse_args()

    if not os.path.exists(args.pkl):
        print("Pickle file not found:", args.pkl)
        sys.exit(1)

    print("Loading pickle:", args.pkl)
    data = load_encoded_file(args.pkl)

    print("\n--- Structure & Sample Stats ---")
    stats = summarize(data, sample_frames=args.sample_frames)

    print("\n--- Determinism checks ---")
    bstable = compare_pickles_bytes(args.pkl)
    print("Byte-level file repeatable read:", bstable)
    # deep compare loaded objects
    data2 = load_encoded_file(args.pkl)
    deep_ok = deep_compare_loaded(data, data2)
    print("Deep-compare loaded structures identical:", deep_ok)

    if args.npz:
        re_ok = reencode_and_compare(data, args.npz, recheck_frames=args.recheck_frames)
        print("Re-encode verification result:", re_ok)

    print("\nDone.")

if __name__ == "__main__":
    main()
